{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "CNN for single bee recognition.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db73jZpeEWBc",
        "colab_type": "text"
      },
      "source": [
        "#Import usefull packages and libraris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtS3nCXxAjc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pdb\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas  as pd\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox5c7kFWEiYN",
        "colab_type": "text"
      },
      "source": [
        "#Mount the drive and read the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlejX-L1EpGo",
        "colab_type": "code",
        "outputId": "709d5035-b888-4166-f38e-56fc032300ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/prime_project/data/'  # your new root path"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "1MFByp3OAjc9",
        "colab_type": "text"
      },
      "source": [
        "# Loading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f39hBfI5AjdB",
        "colab_type": "text"
      },
      "source": [
        "We load the The BeeImage Dataset from Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D630R2l6AjdC",
        "colab_type": "code",
        "outputId": "6411458c-cfbc-449a-8753-601a85211924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "df = pd.read_csv(root_path+\"bee_data.csv\")\n",
        "n_tot = df['file'].count()\n",
        "print(\"Total images in the dataset: {}\".format(n_tot))\n",
        "df.head()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total images in the dataset: 5172\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>location</th>\n",
              "      <th>zip code</th>\n",
              "      <th>subspecies</th>\n",
              "      <th>health</th>\n",
              "      <th>pollen_carrying</th>\n",
              "      <th>caste</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>041_066.png</td>\n",
              "      <td>8/28/18</td>\n",
              "      <td>16:07</td>\n",
              "      <td>Alvin, TX, USA</td>\n",
              "      <td>77511</td>\n",
              "      <td>-1</td>\n",
              "      <td>hive being robbed</td>\n",
              "      <td>False</td>\n",
              "      <td>worker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>041_072.png</td>\n",
              "      <td>8/28/18</td>\n",
              "      <td>16:07</td>\n",
              "      <td>Alvin, TX, USA</td>\n",
              "      <td>77511</td>\n",
              "      <td>-1</td>\n",
              "      <td>hive being robbed</td>\n",
              "      <td>False</td>\n",
              "      <td>worker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>041_073.png</td>\n",
              "      <td>8/28/18</td>\n",
              "      <td>16:07</td>\n",
              "      <td>Alvin, TX, USA</td>\n",
              "      <td>77511</td>\n",
              "      <td>-1</td>\n",
              "      <td>hive being robbed</td>\n",
              "      <td>False</td>\n",
              "      <td>worker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>041_067.png</td>\n",
              "      <td>8/28/18</td>\n",
              "      <td>16:07</td>\n",
              "      <td>Alvin, TX, USA</td>\n",
              "      <td>77511</td>\n",
              "      <td>-1</td>\n",
              "      <td>hive being robbed</td>\n",
              "      <td>False</td>\n",
              "      <td>worker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>041_059.png</td>\n",
              "      <td>8/28/18</td>\n",
              "      <td>16:07</td>\n",
              "      <td>Alvin, TX, USA</td>\n",
              "      <td>77511</td>\n",
              "      <td>-1</td>\n",
              "      <td>hive being robbed</td>\n",
              "      <td>False</td>\n",
              "      <td>worker</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          file     date   time  ...             health  pollen_carrying   caste\n",
              "0  041_066.png  8/28/18  16:07  ...  hive being robbed            False  worker\n",
              "1  041_072.png  8/28/18  16:07  ...  hive being robbed            False  worker\n",
              "2  041_073.png  8/28/18  16:07  ...  hive being robbed            False  worker\n",
              "3  041_067.png  8/28/18  16:07  ...  hive being robbed            False  worker\n",
              "4  041_059.png  8/28/18  16:07  ...  hive being robbed            False  worker\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Oe7DYkwAjdF",
        "colab_type": "text"
      },
      "source": [
        "# Data pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_nnlVICAjdG",
        "colab_type": "text"
      },
      "source": [
        "For the purposes of the current work, we are only interested in associating each bee to the proper subspecies. For this reason, we are going to discard the images repsenting bees whose subspecies is unknown."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXbbHLTnAjdH",
        "colab_type": "code",
        "outputId": "a792e066-bcae-4e7b-fcb2-48082d9dbbda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "df = df[df['subspecies'] != '-1']\n",
        "print(\"Images left: {}\\nImages lost: {}%\".format(df['file'].count(), 100-df['file'].count()/n_tot*100))\n",
        "print(\"Distinct values of subspecies = {}\\n\".format(df[\"subspecies\"].nunique()))\n",
        "print(\"Counting the distinct values of subspecies:\\n{}\".format(df[\"subspecies\"].value_counts()))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images left: 4744\n",
            "Images lost: 8.275328692962105%\n",
            "Distinct values of subspecies = 6\n",
            "\n",
            "Counting the distinct values of subspecies:\n",
            "Italian honey bee        3008\n",
            "Russian honey bee         527\n",
            "Carniolan honey bee       501\n",
            "1 Mixed local stock 2     472\n",
            "VSH Italian honey bee     199\n",
            "Western honey bee          37\n",
            "Name: subspecies, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z624GVLAAjdK",
        "colab_type": "text"
      },
      "source": [
        "We need to pre-process the data in order to have a dataset composed by squared images of the same size. For this reason, we add black pixels as padding whenever the image is not square-shaped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WScWItgBAjdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "\n",
        "def resize_image_padding(img, desired_size=64):\n",
        "    old_size = img.shape[:2]\n",
        "    ratio = float(desired_size)/max(old_size)\n",
        "    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "\n",
        "    img = cv2.resize(img, (new_size[1], new_size[0]))\n",
        "\n",
        "    delta_w = desired_size - new_size[1]\n",
        "    delta_h = desired_size - new_size[0]\n",
        "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "\n",
        "    color = [0, 0, 0]\n",
        "    new_img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
        "    return new_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_ToVTDqAjdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 64\n",
        "\n",
        "directory = root_path+\"/bee_imgs/\"\n",
        "X = []\n",
        "for row in df.file.values:\n",
        "    img = cv2.imread(directory + row, cv2.IMREAD_COLOR) \n",
        "    img = np.array(img)\n",
        "    img = resize_image_padding(img, input_size)\n",
        "    X.append(img)\n",
        "X = np.array(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4My5jB-IAjdR",
        "colab_type": "text"
      },
      "source": [
        "We also need to encode the labels with integer values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13-vXdUIAjdS",
        "colab_type": "code",
        "outputId": "885df3cd-2c49-4a80-961d-734dd925e54f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df.subspecies.values)\n",
        "y = np.array(y)\n",
        "print(y)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 2 2 ... 5 5 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnuYH0ETAjdU",
        "colab_type": "text"
      },
      "source": [
        "Now we can finally split the data for training and testing purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aPXyxwyAjdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=2020)\n",
        "\n",
        "#transform the target in OHE in order to be trained using a softmax activation function\n",
        "Y_train = to_categorical(Y_train)\n",
        "Y_test = to_categorical(Y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfd7PAVwAjda",
        "colab_type": "code",
        "outputId": "7155faa1-a879-4a1b-c19a-95702ef20b4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"X_train.shape = {}\\nX_test.shape = {}\\ny_train.shape = {}\\ny_test.shape ={}\"\n",
        "      .format(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape))"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train.shape = (3795, 64, 64, 3)\n",
            "X_test.shape = (949, 64, 64, 3)\n",
            "y_train.shape = (3795, 6)\n",
            "y_test.shape =(949, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZpk2AqOAjdd",
        "colab_type": "text"
      },
      "source": [
        "# Building the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7J23myYXXDL",
        "colab_type": "text"
      },
      "source": [
        "Define the network structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_iorHUV8cwL",
        "colab_type": "code",
        "outputId": "62cc4608-a45e-4a5b-a513-c936a503bdf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.reset_default_graph()\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import optimizers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "print(keras.__version__)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zkfo7KlW84S3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "n_epochs = 5\n",
        "batch_size = 64\n",
        "\n",
        "# number of convolutional filters to use\n",
        "nb_filters = 32\n",
        "# convolution kernel size\n",
        "kernelSize = (3, 3)\n",
        "# size of pooling area for max pooling\n",
        "pool_size = (2, 2)\n",
        "\n",
        "img_rows, img_cols, nb_channels = input_size,input_size, 3\n",
        "input_shape = (img_rows, img_cols, nb_channels)\n",
        "#number of calsses\n",
        "nb_classes = 6# Y_train.shape[1]\n",
        "# --- Size of the successice layers\n",
        "n_h_0 = nb_channels\n",
        "n_h_1 = nb_filters\n",
        "n_h_2 = nb_filters\n",
        "n_h_3 = nb_filters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycuKU1mGAjde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "filter_size = (3,3)\n",
        "#the initialization of the kernel influences a lot the performance of the algorithm: different initializers have different impact.\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu',padding= \"same\",kernel_initializer= keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None), input_shape=input_shape))\n",
        "\n",
        "model.add(Conv2D(filters = nb_filters, kernel_size = filter_size, activation='relu',padding =\"same\", kernel_initializer= \"random_uniform\",name='conv_2'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters = nb_filters, kernel_size = filter_size, activation='relu',padding =\"same\",kernel_initializer= \"random_uniform\", name='conv_3'))\n",
        "model.add(MaxPooling2D((2, 2), padding=\"same\"))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(nb_classes, activation='softmax', name='dense_1'))\n",
        "\n",
        "# --- END CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HCpScWDXfCQ",
        "colab_type": "text"
      },
      "source": [
        "compile the model, define the loss and the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUksLBc3XiZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=learning_rate),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwtMGgkzXvhv",
        "colab_type": "text"
      },
      "source": [
        "summary of the model to have an idea of the architechture and the weigths that will be trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-a4ZbMaX8E5",
        "colab_type": "code",
        "outputId": "1e663d49-e98b-43d4-a6af-d2e27a3cb06b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "#the number of trainable of parameters at each layers is equal to total number of weight of all the filters at each layer.\n",
        "#In this case 3*3(size of each filter) * 3(depth of each filter)*32(total number of filters at the first layer) + 32(each filter has a bias) = 896\n",
        "model.summary()"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 64, 64, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv_2 (Conv2D)              (None, 64, 64, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv_3 (Conv2D)              (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 49158     \n",
            "=================================================================\n",
            "Total params: 68,550\n",
            "Trainable params: 68,550\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8wQiW75YBhk",
        "colab_type": "text"
      },
      "source": [
        "train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqYKidtvX_Hk",
        "colab_type": "code",
        "outputId": "bd33e2be-6fb6-49f2-f093-1956ad7e8b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "print(X_test.shape,Y_test.shape)\n",
        "model.fit(X_train, Y_train,\n",
        "           batch_size=batch_size, \n",
        "          nb_epoch=n_epochs,\n",
        "          verbose=1, \n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(949, 64, 64, 3) (949, 6)\n",
            "Train on 3795 samples, validate on 949 samples\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-162-112b0ac26daf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           validation_data=(X_test, Y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2931\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2932\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2933\u001b[0;31m                                 session)\n\u001b[0m\u001b[1;32m   2934\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2883\u001b[0m             \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2884\u001b[0m         \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2885\u001b[0;31m         \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2886\u001b[0m         \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m         \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1503\u001b[0m     \"\"\"\n\u001b[1;32m   1504\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1458\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m         self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1460\u001b[0;31m             session._session, options_ptr)\n\u001b[0m\u001b[1;32m   1461\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Tensor conv2d_3_input:0, specified in either feed_devices or fetch_devices was not found in the Graph"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwsDYp8lYHK8",
        "colab_type": "text"
      },
      "source": [
        "evaluate the performances of the model on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqNS_g1eYLaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=False)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbPsr1ncYUno",
        "colab_type": "text"
      },
      "source": [
        "let's have a look to what the network have learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgBg8dRNYdDI",
        "colab_type": "text"
      },
      "source": [
        "plot the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzP7rcV_YUDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}